<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Deprecated | Documentation</title>
    <meta name="description" content="CloudLinux Documentation">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="icon" href="/favicon.ico">
    
    <link rel="preload" href="/assets/css/0.styles.1c9cd124.css" as="style"><link rel="preload" href="/assets/js/app.da36fadb.js" as="script"><link rel="preload" href="/assets/js/13.14de4ed9.js" as="script"><link rel="prefetch" href="/assets/js/10.1942d0f0.js"><link rel="prefetch" href="/assets/js/11.e59dcd5a.js"><link rel="prefetch" href="/assets/js/12.90ac86c3.js"><link rel="prefetch" href="/assets/js/14.21abeab5.js"><link rel="prefetch" href="/assets/js/15.62e779e0.js"><link rel="prefetch" href="/assets/js/16.81b2b2ef.js"><link rel="prefetch" href="/assets/js/17.23b99257.js"><link rel="prefetch" href="/assets/js/18.a999b8b6.js"><link rel="prefetch" href="/assets/js/19.807aaab3.js"><link rel="prefetch" href="/assets/js/20.416e8ee9.js"><link rel="prefetch" href="/assets/js/21.c5366768.js"><link rel="prefetch" href="/assets/js/22.5fdff440.js"><link rel="prefetch" href="/assets/js/23.6d470fbc.js"><link rel="prefetch" href="/assets/js/24.0992162f.js"><link rel="prefetch" href="/assets/js/25.d65e4653.js"><link rel="prefetch" href="/assets/js/26.4be4ef64.js"><link rel="prefetch" href="/assets/js/27.610114bb.js"><link rel="prefetch" href="/assets/js/28.9f51bd74.js"><link rel="prefetch" href="/assets/js/29.266f7b10.js"><link rel="prefetch" href="/assets/js/3.73c3ee7b.js"><link rel="prefetch" href="/assets/js/30.e00a63b3.js"><link rel="prefetch" href="/assets/js/31.0430cb93.js"><link rel="prefetch" href="/assets/js/32.0c319e0d.js"><link rel="prefetch" href="/assets/js/33.65e63c27.js"><link rel="prefetch" href="/assets/js/34.0c068616.js"><link rel="prefetch" href="/assets/js/35.a9cbe4c7.js"><link rel="prefetch" href="/assets/js/36.69d70537.js"><link rel="prefetch" href="/assets/js/37.08289e92.js"><link rel="prefetch" href="/assets/js/38.aab72032.js"><link rel="prefetch" href="/assets/js/39.d54086d4.js"><link rel="prefetch" href="/assets/js/4.c5f4be1b.js"><link rel="prefetch" href="/assets/js/40.988b7b70.js"><link rel="prefetch" href="/assets/js/41.6dd6c2ef.js"><link rel="prefetch" href="/assets/js/42.0e74a0c5.js"><link rel="prefetch" href="/assets/js/43.3391aaae.js"><link rel="prefetch" href="/assets/js/44.da2ddf64.js"><link rel="prefetch" href="/assets/js/45.67142dec.js"><link rel="prefetch" href="/assets/js/46.286cface.js"><link rel="prefetch" href="/assets/js/47.b4b24a87.js"><link rel="prefetch" href="/assets/js/48.733fe4cb.js"><link rel="prefetch" href="/assets/js/49.022233ca.js"><link rel="prefetch" href="/assets/js/5.5ac32b68.js"><link rel="prefetch" href="/assets/js/50.0b06a7da.js"><link rel="prefetch" href="/assets/js/51.e69716c2.js"><link rel="prefetch" href="/assets/js/6.788f7cb0.js"><link rel="prefetch" href="/assets/js/7.bb646a5c.js"><link rel="prefetch" href="/assets/js/8.d60f6fd1.js"><link rel="prefetch" href="/assets/js/9.d765786c.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.f089aea3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.1c9cd124.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><section class="navbar"><header class="navbar__header"><section class="navbar__block"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.svg" alt="Documentation" class="logo"> <img src="/logo-short.svg" alt="Documentation" class="logo-short"></a> <div class="site-name">
        Documentation
      </div> <form id="search-form" class="algolia-search-wrapper search-box"><input id="algolia-search-input" placeholder="Search" class="search-query"></form></section> <section class="navbar__block"><button class="menu-btn menu-btn--products-list"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon icon--products-list"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg>
        Products
      </button> <button class="navbar-btn navbar-btn--submit-request">Submit request</button> <div class="links" style="max-width:nullpx;"><a href="https://cloudlinux.com/trial" target="_blank" class="navbar-btn navbar-btn--try-free">Try Free</a> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><span class="title">Language:</span> <a class="dropdown-title"><span class="text">En</span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/deprecated/" class="nav-link router-link-exact-active router-link-active">English</a></li><li class="dropdown-item"><!----> <a href="/ru/deprecated/" class="nav-link">Русский</a></li></ul></div></div></nav></div></section></header> <!----></section> <div class="sidebar-mask"></div> <div class="sidebar"> <ul class="sidebar-links"><li><div class="sidebar-group first"><div class="sidebar-heading open"><span>Content</span> <!----></div> <ul class="sidebar-group-items"><li><a href="/single/introduction/" class="sidebar-link">Introduction</a></li><li><a href="/single/installation/" class="sidebar-link">Installation</a></li><li><a href="/single/manager/" class="sidebar-link">CloudLinux Manager</a></li></ul></div></li></ul> </div> <div class="page"> <div class="breadcrumb-wrapper page-breadcrumb" data-v-5e0e0acf><span class="breadcrumb-title" data-v-5e0e0acf>Documentation:</span> <a href="/deprecated/" class="breadcrumb router-link-exact-active router-link-active" data-v-5e0e0acf>
    Deprecated
  </a></div> <div class="page-nav-wrapper"><!----></div> <div class="content content__default"><h1 id="deprecatedbeta"><a href="#deprecatedbeta" class="header-anchor">#</a> Deprecated<sup>Beta</sup></h1> <ul><li><a href="/deprecated/#git-for-cpanel">Git for cPanel</a></li> <li><a href="/deprecated/#lve-stats-0-x">LVE-Stats 0.x</a></li> <li><a href="/deprecated/#optimumcache">OptimumCache</a></li> <li><a href="/deprecated/#tpe-extension">TPE extension</a></li> <li><a href="/deprecated/#cpu-limits">CPU limits</a></li></ul> <h2 id="git-for-cpanel"><a href="#git-for-cpanel" class="header-anchor">#</a> Git for cPanel</h2> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>This package is no longer supported as it may cause dependency issues</p></div><p>Please note that this package is no longer needed, as since cPanel 11.38, you can install git without any issues on cPanel by running:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum install git
</code></pre></div></div> <p>To install <a href="http://git-scm.com/" target="_blank" rel="noopener noreferrer">git<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> on cPanel servers:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum install git-cpanel
</code></pre></div></div> <h2 id="lve-stats-0-x"><a href="#lve-stats-0-x" class="header-anchor">#</a> LVE-Stats 0.x</h2> <ul><li><a href="/deprecated/#storing-statistics-in-mysql">Storing statistics in MySQL</a></li> <li><a href="/deprecated/#storing-statistics-in-postgresql">Storing statistics in PostgreSQL</a></li> <li><a href="/deprecated/#compacting-in-multi-server-settings">Compacting in multi-server settings</a></li></ul> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>LVE-STATS-0.X IS NO LONGER SUPPORTED, PLEASE USE <a href="/lve-stats_2/">LVE-STATS 2</a></p></div><p>lve-stats package collects LVE usage statistics and allows to query the data.</p> <p>To install, run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum install lve-stats
</code></pre></div></div> <p>If you are already running lve-stats (in case you are running cPanel LVE plugin), run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum update lve-stats
</code></pre></div></div> <p>This should also be updated automatically next time your system runs system wide update.</p> <p>The package installs lvestats-server. You can re-start the server by running:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ service lvestats restart
</code></pre></div></div> <p>The package creates sqlite database <span class="notranslate"><code>/var/lve/lveinfo.db</code></span> that stores history information about LVE usage. Up to two months of hourly info is stored for each client. The data for the last hour is stored with 5 minutes interval, and the data for the past 10 minutes is stored with 1 minute interval.</p> <p>LVE Stats updates <span class="notranslate"><code>/var/lve/info</code></span> every few seconds. That info is used by <span class="notranslate">LVE Manager</span> plugin.</p> <p>Package consists of lveinfo utility to query LVE usage, and lvechart that allows you to chart usage for individual LVE.</p> <p>To query historical LVE info, lveinfo command provided. It is located at <span class="notranslate"><code>/usr/sbin/lveinfo</code></span>:
 
</p><div class="notranslate"><p></p> <div class="language- extra-class"><pre class="language-text"><code># /usr/sbin/lveinfo [OPTIONS]
-h --help              : this help screen
-v, --version          : version number
-d, --display-username : try to convert LVE id into username when possible
-f, --from=            : run report from date and time in YYYY-MM-DD HH:MM format
      if not present last 10 minutes are assumed
-t, --to=              : run report up to date and time in YYYY-MM-DD HH:MM format
      if not present, reports results up to now
-o, --order-by=        : orders results by one of the following:
      cpu_avg          : average CPU usage
      cpu_max          : max CPU usage
      mep_avg          : average number of entry processes (concurrent connections)
      mep_max          : max number of entry processes (concurrent connections)
      vmem_avg         : average virtual memory usage
      vmem_max         : max virtual memory usage
      pmem_avg         : average physical memory usage
      pmem_max         : max physical memory usage
      nproc_avg        : average number of processes usage
      nproc_max        : max number of processes usage
      io_avg           : average IO usage
      io_max           : max IO usage
      total_mem_faults : total number of out of virtual memory faults (deprecated since 0.8-6)
      total_vmem_faults: total number of out of virtual memory faults (since 0.8-6)
      total_pmem_faults: total number of out of physical memory faults (since 0.8-6)
      total_mep_faults : total number of entry processes faults (deprecated since 0.8-6)
      total_ep_faults  : total number of entry processes faults (since 0.8-6)
      total_nproc_faults: total number of number of processes faults (since 0.8-6)
      any_faults       : total number of any types of faults (since 0.8-6)
    --id=              : LVE id -- will display record only for that LVE id
-u, --user=            : Use username instead of LVE id, and show only record for that user
-l, --limit=           : max number of results to display, 10 by default
-c, --csv              : display output in CSV format
-b, --by-usage         : show LVEs with usage (averaged or max) within 90% percent of the limit
      available values:
      cpu_avg          : average CPU usage
      cpu_max          : max CPU usage
      mep_avg          : average number of entry processes (concurrent connections)
      ep_avg           : average number of entry processes (since 0.8-6)
      mep_max          : max number of entry processes (concurrent connections)
      ep_max           : max number of entry processes (since 0.8-6)
      mem_avg          : average virtual memory usage
      mem_max          : max virtual memory usage
      vmem_avg         : average virtual memory usage
      vmem_max         : max virtual memory usage
      pmem_avg         : average physical memory usage
      pmem_max         : max physical memory usage
      nproc_avg        : average number of processes
      nproc_max        : max number of processes
      io_avg           : average IO usage
      io_max           : max IO usage
-p, --percentage       : defines percentage for --by-usage option
-f, --by-fault         : show LVEs which failed on max entry processes limit or memory limit
      available values: mem, mep.
      since 0.8-6      : vmem, pmem, ep, nproc
    --show-all         : since 0.8-6 only columns for enabled limits will show up. 
-r, --threshold        : in combination with --by-fault, shows only LVEs with number of faults above threshold specified
    --server_id        : used in combination with centralized storage, to access info from any server
    --show-all         : full output (show all limits); brief output by default
</code></pre></div></div> <p><strong>Output</strong></p> <table><thead><tr><th></th> <th></th></tr></thead> <tbody><tr><td>ID</td> <td>LVE Id or username</td></tr> <tr><td>aCPU</td> <td>Average CPU usage</td></tr> <tr><td>mCPU</td> <td>Max CPU usage</td></tr> <tr><td>lCPU</td> <td>CPU Limit</td></tr> <tr><td>aEP</td> <td>CPU Limit</td></tr> <tr><td>mEP</td> <td>Max Entry Processes</td></tr> <tr><td>lEP</td> <td>Entry Proc limit</td></tr> <tr><td>aNPROC</td> <td>Average Number of Processes</td></tr> <tr><td>mNPROC</td> <td>Max Number of Processes</td></tr> <tr><td>lNPROC</td> <td>Number of Processes limit</td></tr> <tr><td>aVMEM</td> <td>Average virtual Memory Usage</td></tr> <tr><td>mVMEM</td> <td>Max virtual Memory Usage</td></tr> <tr><td>lVMEM</td> <td>Virtual Memory Limit</td></tr> <tr><td>aPMEM</td> <td>Average physical Memory Usage</td></tr> <tr><td>mPMEM</td> <td>Max physical Memory Usage</td></tr> <tr><td>lPMEM</td> <td>Physical Memory Limit</td></tr> <tr><td>aIO</td> <td>Average IO usage</td></tr> <tr><td>mIO</td> <td>Max IO usage</td></tr> <tr><td>lIO</td> <td>IO Limit</td></tr> <tr><td>fVMEM</td> <td>Out Of Virtual Memory Faults</td></tr> <tr><td>fPMEM</td> <td>Out Of Physical Memory Faults</td></tr> <tr><td>fEP</td> <td>Entry processes faults</td></tr> <tr><td>fNPROC</td> <td>Number of processes faults</td></tr></tbody></table> <ul><li>only enabled limits will show up</li></ul> <p><strong>Examples</strong></p> <p>Display top 10 users, by max <span class="notranslate"> CPU </span> usage, from Oct 10, 2010 to Oct 15, 2010. Display username if possible:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ lveinfo --from='2010-10-10' --to='2010-10-15' -o cpu_max --display-username 
ID        aCPU       mCPU     lCPU      aEP      mEP      lEP       aMem       mMem      lMem      MemF     MepF 
777         7        9        10        0        0        25        10M        15M       1G        0        0 
300         2        8        10        0        1        25        1M         3M        1G        0        0 
web2        1        6        10        0        0        25        17K        18M       1G        0        0 
web1        0        0        10        0        0        25        204K       1M        1G        0        0 
</code></pre></div></div>
Display LVE info about user <span class="notranslate"> web2 </span> , from Oct 10, 2010 to Oct 15, 2010:
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ lveinfo --from='2010-10-10' --to='2010-10-15' --user=web2 --display-username
ID        aCPU       mCPU     lCPU      aEP      mEP      lEP       aMem       mMem       lMem      MemF     MepF 
web2        1        6        10        0        0        25        10M        15M        1G        0        0
</code></pre></div></div> <h3 id="storing-statistics-in-mysql"><a href="#storing-statistics-in-mysql" class="header-anchor">#</a> Storing statistics in MySQL</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>LVE-STATS-0.X IS NO LONGER SUPPORTED, PLEASE USE <a href="/lve-stats_2/">LVE-STATS 2</a></p></div><p>You have to install MySQL-python rpm to store lve-stats on centralized server. Run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum install MySQL-python
</code></pre></div></div> <p>If you have MySQL 5.3+ installed on CloudLinux 5 server, and there is no libmysqlclient_r.so.15 on the server, run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum --enablerepo=cloudlinux-updates-testing install mysqlclient15
</code></pre></div></div> <p>A typical procedure to configure the MySQL database for storing information about multiple servers for lve-stats services looks as follows:</p> <p>Create database and user. You can do it by executing the following commands:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>create database &lt;database&gt;;
grant all on &lt;database&gt;.* to &lt;user&gt; identified by 'password';
flush privileges;
</code></pre></div></div> <p>Create database schema:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>CREATE TABLE history (id INTEGER,
        cpu INTEGER, cpu_limit INTEGER,
        cpu_max INTEGER,
        ncpu INTEGER,
        mep INTEGER, mep_limit INTEGER,
        mep_max INTEGER,
        io INTEGER, io_limit INTEGER,
        mem INTEGER, mem_limit INTEGER,
        mem_max INTEGER,
        mem_fault INTEGER, mep_fault INTEGER,
        created TIMESTAMP, weight INTEGER, server_id CHAR(10),
        lmemphy INTEGER, memphy INTEGER, memphy_max INTEGER, memphy_fault INTEGER,
        lnproc INTEGER, nproc INTEGER, nproc_max INTEGER, nproc_fault INTEGER,
        lcpuw INTEGER, io_max INTEGER,
        iops INTEGER, liops INTEGER, iops_max INTEGER );
CREATE INDEX idx_history_id ON history(id);
CREATE INDEX idx_history_created ON history(created);
CREATE INDEX idx_history_weight ON history(weight);
CREATE INDEX idx_history_server_id ON history(server_id);
CREATE TABLE last_run (hourly TIMESTAMP, daily TIMESTAMP, server_id CHAR(10), lve_version INTEGER);
CREATE TABLE users (server_id CHAR(10), id INTEGER, username CHAR(20));
CREATE INDEX idx_users_server_id ON users(server_id);
CREATE INDEX idx_users_id ON users(id); 

CREATE TABLE history_gov ( ts INTEGER,
                           username CHAR(64),
                           max_simultaneous_requests INTEGER,
                           sum_cpu FLOAT,
                           sum_write FLOAT,
                           sum_read FLOAT,
                           number_of_iterations INTEGER,
                           max_cpu FLOAT,
                           max_write FLOAT,
                           max_read FLOAT,
                           number_of_restricts INTEGER,
                           limit_cpu_on_period_end INTEGER,
                           limit_read_on_period_end INTEGER,
                           limit_write_on_period_end INTEGER,
                           cause_of_restrict INTEGER,
                           weight INTEGER,
                           server_id char(10)); 

CREATE INDEX idx_history_gov_ts ON history_gov(ts);
CREATE INDEX idx_history_gov_cause_of_restrict ON history_gov(cause_of_restrict);
CREATE INDEX idx_history_gov_number_of_restricts ON history_gov(number_of_restricts); 
CREATE INDEX idx_history_gov_max_simultaneous_requests ON history_gov(max_simultaneous_requests);
CREATE INDEX idx_history_gov_server_id ON history_gov(server_id);
CREATE INDEX idx_history_gov_weight ON history_gov(weight);

CREATE TABLE last_run_gov (hourly TIMESTAMP, daily TIMESTAMP, server_id CHAR(10), lve_version INTEGER);


* Execute following SQL command for each remote server for which you want to store
statistics in this database (make sure you substitute _SERVER_NAME_ with the same
servername as used in lvestats config file on remote server: 

INSERT INTO last_run(hourly, daily, server_id, lve_version) VALUES (UTC_TIMESTAMP(), UTC_TIMESTAMP(), '_SERVER_NAME_', 4);
</code></pre></div></div> <p>On each server edit file <span class="notranslate"><code>/etc/sysconfig/lvestats</code></span> &amp; <span class="notranslate"><code>/etc/sysconfig/lvestats.readonly</code></span> as follows:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>db_type = mysql
connect_string = host:database:user:password
server_id = _SERVER_NAME_
db_port = _port_
</code></pre></div></div> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>lvestats.readonly should have a user that has read only access to all tables from lvestats database.</p></div><div class="tip custom-block"><p class="custom-block-title">Note</p><p><em>SERVER_NAME</em> should be at most 10 characters</p></div><div class="tip custom-block"><p class="custom-block-title">Note</p><p>db_port is an optional parameter. Default port would be used.</p></div><p>Select server responsible for compacting database on regular bases by setting <span class="notranslate"><code>COMPACT=master</code></span> in <span class="notranslate"><code>/etc/sysconfig/lvestats</code></span> for that server. Set <span class="notranslate"> COMPACT=slave </span> on all other servers.</p> <p>Make sure that <span class="notranslate"><code>/etc/sysconfig/lvestats</code></span> is readable only by <span class="notranslate"><code>root (chmod 600 /etc/sysconfig/lvestats), lvestats.readonly</code></span> should be readable by anyone</p> <p>Restart service:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>service lvestats restart
</code></pre></div></div> <p>If you use central database to store lvestats data, on each server, execute:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ /usr/share/lve-stats/save_users_to_database.py 
</code></pre></div></div> <p>You just need to execute it once, as it will be later executed via <span class="notranslate"> cron job </span> . That script will store usernames from each server, so that lve-stats would later be able to correctly identify each user.</p> <p><strong>Updating MySQL &amp; PostgreSQL schema for lve-stats 0.8+</strong></p> <p>If you are using MySQL or PostgreSQL server for lve-stats older then 0.8, make sure to do the following steps to upgrade to latest version:</p> <p>Stop lvestats service on all your servers.</p> <p>Connect to your database server, and execute following commands:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>ALTER TABLE history ADD lmemphy INTEGER;
ALTER TABLE history ADD memphy INTEGER;
ALTER TABLE history ADD memphy_max INTEGER;
ALTER TABLE history ADD memphy_fault INTEGER;
ALTER TABLE history ADD lnproc INTEGER;
ALTER TABLE history ADD nproc INTEGER;
ALTER TABLE history ADD nproc_max INTEGER;
ALTER TABLE history ADD nproc_fault INTEGER;
ALTER TABLE history ADD lcpuw INTEGER;
ALTER TABLE history ADD io_max INTEGER;
UPDATE history SET lmemphy = 0, memphy = 0, memphy_max = 0, memphy_fault = 0,
       lnproc = 0, nproc = 0, nproc_max = 0, nproc_fault = 0,
       lcpuw = 0, io_max = 0;

ALTER TABLE last_run ADD lve_version INTEGER;
UPDATE last_run SET lve_version = 4;
CREATE TABLE last_run_gov (hourly TIMESTAMP, daily TIMESTAMP, server_id CHAR(10), lve_version INTEGER);
</code></pre></div></div>
To upgrade scheme to support <span class="notranslate"> MySQL Governor: </span> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>CREATE TABLE history_gov ( ts INTEGER,
    username char(64),
    max_simultaneous_requests INTEGER,
    sum_cpu float,
    sum_write float,
    sum_read float,
    number_of_iterations INTEGER,
    max_cpu float,
    max_write float,
    max_read float,
    number_of_restricts INTEGER,
    limit_cpu_on_period_end INTEGER,
    limit_read_on_period_end INTEGER,
    limit_write_on_period_end INTEGER,
    cause_of_restrict INTEGER,
    server_id char(10));

CREATE INDEX idx_history_gov_ts ON history_gov(ts);
CREATE INDEX idx_history_gov_cause_of_restrict ON history_gov(cause_of_restrict);
CREATE INDEX idx_history_gov_number_of_restricts ON history_gov(number_of_restricts);
CREATE INDEX idx_history_gov_max_simultaneous_requests ON history_gov(max_simultaneous_requests);
CREATE INDEX idx_history_gov_server_id ON history_gov(server_id);
</code></pre></div></div>
Upgrading from lve-stats &lt; 0.9-20:
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>ALTER TABLE history_gov ADD weight INTEGER;
CREATE INDEX idx_history_gov_weight ON history_gov(weight);
CREATE TABLE last_run_gov (hourly TIMESTAMP, daily TIMESTAMP, server_id CHAR(10), lve_version INTEGER);
</code></pre></div></div>
Update lve-stats RPM on all your servers.
<p>If you use central database to store lvestats data, execute the following commands:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>CREATE TABLE users (server_id CHAR(10), id INTEGER, username CHAR(20));CREATE INDEX idx_users_server_id ON users(server_id);CREATE INDEX idx_users_id ON users(id);
</code></pre></div></div>
On each server execute:
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ /usr/share/lve-stats/save_users_to_database.py 
</code></pre></div></div> <p>You just need to execute it once, as it will be later executed via cron job. That script will store usernames from each server, so that lve-stats would later be able to correctly identify each user.</p> <h3 id="storing-statistics-in-postgresql"><a href="#storing-statistics-in-postgresql" class="header-anchor">#</a> Storing statistics in PostgreSQL</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>LVE-STATS-0.X IS NO LONGER SUPPORTED, PLEASE USE <a href="/lve-stats_2/">LVE-STATS 2</a></p></div><p>You have to install <span class="notranslate"><code>postgresql-python rpm</code></span> to store lve-stats on centralized server.</p> <p>Run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ yum install postgresql-python
</code></pre></div></div> <p>A typical procedure to configure the PostgreSQL database for storing information about multiple servers for lve-stats services looks as follows:</p> <p>Create a database and a user. You can do it by executing the following commands:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>createdb &lt;database&gt;createuser &lt;user&gt;
</code></pre></div></div>
Create database schema:
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>CREATE TABLE history (id INTEGER,
        cpu INTEGER, cpu_limit INTEGER,
        cpu_max INTEGER,
        ncpu INTEGER,
        mep INTEGER, mep_limit INTEGER,
        mep_max INTEGER,
        io INTEGER, io_limit INTEGER,
        mem INTEGER, mem_limit INTEGER,
        mem_max INTEGER,
        mem_fault INTEGER, mep_fault INTEGER,
        created TIMESTAMP, weight INTEGER, server_id CHAR(10),
        lmemphy INTEGER, memphy INTEGER, memphy_max INTEGER, memphy_fault INTEGER,
        lnproc INTEGER, nproc INTEGER, nproc_max INTEGER, nproc_fault INTEGER,
        lcpuw INTEGER, io_max INTEGER,



        iops_max: INTEGER, liops: INTEGER, iops: INTEGER);

CREATE INDEX idx_history_id ON history(id);
CREATE INDEX idx_history_created ON history(created);
CREATE INDEX idx_history_weight ON history(weight);
CREATE INDEX idx_history_server_id ON history(server_id);
CREATE TABLE last_run (hourly TIMESTAMP, daily TIMESTAMP, server_id CHAR(10), lve_version INTEGER);
CREATE TABLE users (server_id CHAR(10), id INTEGER, username CHAR(20));CREATE INDEX idx_users_server_id ON users(server_id);
CREATE INDEX idx_users_id ON users(id);

CREATE TABLE history_gov ( ts INTEGER,
    username char(64),
    max_simultaneous_requests INTEGER,
    sum_cpu float,
    sum_write float,
    sum_read float,
    number_of_iterations INTEGER,
    max_cpu float,
    max_write float,
    max_read float,
    number_of_restricts INTEGER,
    limit_cpu_on_period_end INTEGER,
    limit_read_on_period_end INTEGER,
    limit_write_on_period_end INTEGER,
    cause_of_restrict INTEGER,
    weight INTEGER,
    server_id char(10));

CREATE INDEX idx_history_gov_ts ON history_gov(ts);
CREATE INDEX idx_history_gov_cause_of_restrict ON history_gov(cause_of_restrict);
CREATE INDEX idx_history_gov_number_of_restricts ON history_gov(number_of_restricts);
CREATE INDEX idx_history_gov_max_simultaneous_requests ON history_gov(max_simultaneous_requests);
CREATE INDEX idx_history_gov_server_id ON history_gov(server_id);
CREATE INDEX idx_history_gov_weight ON history_gov(weight);

CREATE TABLE last_run_gov (hourly TIMESTAMP, daily TIMESTAMP, server_id CHAR(10), lve_version INTEGER);

     * Execute following SQL command for each remote server for which you want to store
      statistics in this database (make sure you substitute _SERVER_NAME_ with the same
      servername as used in lvestats config file on remote server:

INSERT INTO last_run(hourly, daily, server_id, lve_version) VALUES (now() AT TIME ZONE 'UTC', now() AT TIME ZONE 'UTC', '_SERVER_NAME_', 4);
</code></pre></div></div>
On each server edit file <span class="notranslate">`/etc/sysconfig/lvestats`</span> and <span class="notranslate">`/etc/sysconfig/lvestats`</span> as follows:
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>db_type = postgresql
connect_string = host:database:user:password
server_id = _SERVER_NAME_db_port = _port_
</code></pre></div></div> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>lvestats.readonly should have a user that has read only access to history table.</p></div><div class="tip custom-block"><p class="custom-block-title">Note</p><p><em>SERVER_NAME</em> should be at most 10 characters</p></div><div class="tip custom-block"><p class="custom-block-title">Note</p><p>db_port is optional, default PostgreSQL port will be used</p></div><p>Select server responsible for compacting database on regular bases by setting <span class="notranslate"> COMPACT=master </span> in <span class="notranslate"> /etc/sysconfig/lvestats </span> for that server. Set <span class="notranslate"> COMPACT=slave </span> on all other servers.</p> <p>Make sure that <span class="notranslate"> /etc/sysconfig/lvestats </span> is readable only by <span class="notranslate"> root (chmod 600 /etc/sysconfig/lvestats), lvestats.readonly </span> should be readable by anyone.</p> <p>Restart service:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>service lvestats restart
</code></pre></div></div>
If you use central database to store lvestats data, on each server, execute:
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ /usr/share/lve-stats/save_users_to_database.py 
</code></pre></div></div>
You just need to execute it once, as it will be later executed via <span class="notranslate"> cron job </span> . That script will store usernames from each server, so that lve-stats would later be able to correctly identify each user.
<p>You are done!</p> <h3 id="compacting-in-multi-server-settings"><a href="#compacting-in-multi-server-settings" class="header-anchor">#</a> Compacting in multi-server settings</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>LVE-STATS-0.X IS NO LONGER SUPPORTED, PLEASE USE <a href="/lve-stats_2/">LVE-STATS 2</a></p></div><p>[lve-stats 0.10+]</p> <p>When you have multiple servers storing LVE statistics to a central database, then you will need to pick one server responsible for compacting data.</p> <p>On that server, edit file: <span class="notranslate"><code>/etc/sysconfig/lvestats</code></span> and change the option <span class="notranslate"><code>COMPACT</code></span> to <span class="notranslate"><code>master</code></span>.</p> <p>On all other servers, change that option to <span class="notranslate"><code>slave</code></span>.</p> <p>Default: <span class="notranslate"><code>single</code></span> – should be used when lve-stats stores data to a single database.</p> <h2 id="optimumcache"><a href="#optimumcache" class="header-anchor">#</a> OptimumCache</h2> <ul><li><a href="/deprecated/#installation">Installation</a> <ul><li><a href="/deprecated/#requirements">Requirements</a></li> <li><a href="/deprecated/#installation-2">Installation</a></li></ul></li> <li><a href="/deprecated/#using-without-ploop">Using without ploop</a></li> <li><a href="/deprecated/#marking-directories">Marking directories</a></li> <li><a href="/deprecated/#optimumcache-configuration-file">OptimumCache configuration file</a></li> <li><a href="/deprecated/#command-line-interface">Command-line interface</a></li> <li><a href="/deprecated/#cloudlinux-collect-collect-system-load-statistics">cloudlinux-collect: collect system load statistics</a> <ul><li><a href="/deprecated/#cloudlinux-collectl-quick-start">cloudlinux-collectl: quick start</a></li> <li><a href="/deprecated/#install">Install</a></li> <li><a href="/deprecated/#measure-web-site-response-time">Measure web site response time</a></li> <li><a href="/deprecated/#to-watch-what-is-being-collected">To watch what is being collected</a></li> <li><a href="/deprecated/#statistics-being-collected-in-details">Statistics being collected in details</a></li> <li><a href="/deprecated/deprecated/#statistics-manual-configuration">Statistics manual configuration</a></li> <li><a href="/deprecated/#running-statistics-daemon-collectl-cloudlinux">Running statistics daemon: collectl-cloudlinux</a></li> <li><a href="/deprecated/#analyzing-the-results">Analyzing the results</a></li></ul></li> <li><a href="/deprecated/deprecated/#uninstall-optimumcache">Uninstall OptimumCache</a></li> <li><a href="/deprecated/#troubleshooting">Troubleshooting</a></li></ul> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED.</p></div><p><strong>OptimumCache 0.2+</strong></p> <p>OptimumCache is a de-duplicating file cache optimized specifically for shared hosting. Typical shared hosting server runs a number of sites with WordPress and Joomla as well as other popular software. This usually means that there are hundreds of duplicate files that are constantly being read into file cache - both wasting precious disk <span class="notranslate"> IO </span> operations as well as memory. OptimumCache creates a cache of such duplicated files and de-duplicates file cache.
<img src="/images/embim1.png" alt=""></p> <p>With OptimumCache, if a duplicate of an already loaded file is requested, the file gets loaded from filesystem cache. By doing that, system bypasses disk IO, significantly improving the speed of reading that file, while lowering load on the hard disk. As the file had been read from disk just once, it is cached by filesystem cache just once, minimizing amount of duplicates in file system cache and improving overall cache efficiency. This in turn reduces memory usage, decreases the number of disk operations - all while improving the websites response time.</p> <p>Further reading: <a href="http://kb.cloudlinux.com/tag/optimumcache/" target="_blank" rel="noopener noreferrer">http://kb.cloudlinux.com/tag/optimumcache/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="installation"><a href="#installation" class="header-anchor">#</a> Installation</h3> <div class="tip custom-block"><p class="custom-block-title">NOTE</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><h4 id="requirements"><a href="#requirements" class="header-anchor">#</a> Requirements</h4> <ul><li>64bit CloudLinux 6.x or higher</li> <li>ext4 filesystem</li> <li>kernel lve1.2.55 or later.</li></ul> <h4 id="installation-2"><a href="#installation-2" class="header-anchor">#</a> Installation</h4> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># yum install optimumcache
</code></pre></div></div> <p>OptimumCache must be provided with list of directories to expect duplicate files be in:</p> <ul><li><span class="notranslate"><code># occtl --recursive --mark-dir /home</code></span></li> <li><span class="notranslate"><code># occtl --recursive --mark-dir /home2</code></span> (for cPanel)</li> <li><span class="notranslate"><code># occtl --recursive --mark-dir /var/www</code></span> (for Plesk)</li></ul> <p>OptimumCache is going to index these directories. Thus system load during this period (from hours to days) might be as twice as high. See <a href="/deprecated/#marking-directories">Marking directories</a>.</p> <p><strong>Allocating Disk Space for OptimumCache:</strong></p> <p>By default OptimumCache will attempt to setup 5GB ploop (high efficiency loopback disk) to be used for the cache in <span class="notranslate"><code>/var/share/optimumcache/optimumcache.image</code></span></p> <p>That ploop will be mounted to: <span class="notranslate"><code>/var/cache/optimumcache</code></span></p> <p>The ploop image will be located at <span class="notranslate"><code>/var/share/optimumcache/optimumcache.image</code></span></p> <p>Allocating OptimumCache disk space for ploop on a fast drives (like SSD) will provide additional performance improvement as more duplicated files would be loaded from fast disks into memory.</p> <p><strong>Moving ploop image to another location:</strong></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --move-ploop /path/to/new/image/file [new size[KMGT]]
</code></pre></div></div> <p><code>/path/to/new/image/file</code> must be file path + file name, not a directory name.</p> <p>Example:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --move-ploop /var/ssh/optimumcache.image
</code></pre></div></div> <p>If <span class="notranslate"><code>new size</code></span> is not mentioned, then value from <span class="notranslate"><code>/etc/sysconfig/optimumcache</code></span> is used. If <span class="notranslate"><code>/etc/sysconfig/optimumcache</code></span> does not mention anything regarding ploop image size, then default 5GB is used.</p> <p><strong>Enabling and disabling ploop:</strong></p> <p>To turn on ploop:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --init-ploop
</code></pre></div></div> <p>To disable ploop:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --disable-ploop
</code></pre></div></div> <p>If ploop image has been mounted in <span class="notranslate"><code>/etc/fstab</code></span> for OpimumCache-0.1-21 and earlier, you may consider removing this fstab entry in OpimumCache 0.2+. That is because since 0.2+ ploop is mounted automatically at service start.</p> <p>If you prefer leave that fstab mount point as is, you may see some warnings when you decide to move ploop later via <span class="notranslate"><code>occtl --move-ploop</code></span>.</p> <p><strong>Resizing ploop:</strong></p> <p>To resize ploop:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --resize-ploop [new size[KMGT]]
</code></pre></div></div> <p>A common reason for resizing ploop is reacting to OptimumCache syslog message like <span class="notranslate">“OptimumCache recommends cache storage size to be at least … GB”</span>.</p> <p><strong>Deleting ploop:</strong></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --delete-ploop
</code></pre></div></div> <p>For the case when this action cannot be completed due to <span class="notranslate">“Unable unmount ploop”</span> issue, there is a workaround in “Troubleshooting” section.</p> <p>Q. I created/resized/moved/deleted ploop. Do I need to rerun the initial mark process?</p> <p>А. Not needed.</p> <h3 id="using-without-ploop"><a href="#using-without-ploop" class="header-anchor">#</a> Using without ploop</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><p>On servers with kernel prior to lve1.2.55 ploop will not be used (due to ploop related issues in the kernel). Instead cached files will be stored in <span class="notranslate"><code>/var/cache/optimumcache</code></span>.</p> <p>The cache will be cleaned (shrunk) by 20% once partition on which <span class="notranslate"><code>OPTIMUMCACHE_MNT</code></span> resides has only 10% of free space. You can change that by changing <span class="notranslate"><code>PURGEAHEAD</code></span> param in <span class="notranslate"><code>/etc/sysconfig/optimumcache</code></span>, and restarting optimumcache service.</p> <p>The cache is cleaned <span class="notranslate"><code>/etc/cron.d/optimumcache_cron</code></span> script optimumcache_purge, which runs every minute:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>0-59 * * * * root /usr/share/optimumcache/optimumcache_purge
</code></pre></div></div> <h3 id="marking-directories"><a href="#marking-directories" class="header-anchor">#</a> Marking directories</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><p><strong>Marking directories to be cached:</strong></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --mark-dir /path/to/site/on/filesystem --recursive
</code></pre></div></div> <p>In common scenario admin marks for caching user directories:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --mark-dir /home /home2 /home3 --recursive
</code></pre></div></div> <p>OptimumCache is going to index these directories. Thus system load during this period (from hours to days) might be as twice as high. You can check indexing job status with <span class="notranslate"><code>at -l</code></span> at any time.</p> <p><strong>Ignoring particular files &amp; directories:</strong></p> <p>OptimumCache tracks files &amp; directories that need to be cached. Once file is modified, it will no longer be tracked by OptimumCache (as there is very little chance that it will have a duplicate). Yet, all new files created in tracked directories are checked for duplicates.</p> <p>Sometimes you might want to ignore such checks for directories where large number of temporary or new files are created, that will not have duplicates - as such checks are expensive. Directories like mail queue, and tmp directories should be ignored.</p> <p>You can set a regexp mask for directories that you would like to ignore using:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ occtl --add-skip-mask REGEX
</code></pre></div></div> <p>To list skip masks:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ occtl --list-skip-mask
</code></pre></div></div> <p>To remove skip mask:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ occtl --remove-skip-mask ID|Tag
</code></pre></div></div> <p>At the very end, for those changes to take effect:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>$ occtl --check
</code></pre></div></div> <p><span class="notranslate"><code>occtl --check</code></span> is the same lengthy operation as <span class="notranslate"><code>marking</code></span> is. Thus, it’s usage has to be sane, especially for big <span class="notranslate"><code>home</code></span> (&gt;500G).</p> <p>By default, OptimumCache sets up following skip masks:</p> <table><thead><tr><th></th> <th></th> <th></th></tr></thead> <tbody><tr><td>id</td> <td>tag</td> <td>regex</td></tr> <tr><td>1</td> <td><span class="notranslate"><code>all_dot_files</code></span></td> <td><span class="notranslate"><code>/\...*</code></span></td></tr> <tr><td>2</td> <td><span class="notranslate"><code>cagefs</code></span></td> <td><span class="notranslate"><code>^/home/cagefs-skeleton$</code></span></td></tr> <tr><td>3</td> <td><span class="notranslate"><code>cagefs</code></span></td> <td><span class="notranslate"><code>^/home/cagefs-skeleton/</code></span></td></tr> <tr><td>4</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/cPanelInstall</code></span></td></tr> <tr><td>5</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/cpeasyapache</code></span></td></tr> <tr><td>6</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/aquota</code></span></td></tr> <tr><td>7</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/jailshell</code></span></td></tr> <tr><td>8</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/mail$</code></span></td></tr> <tr><td>9</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/mail/.*</code></span></td></tr> <tr><td>10</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/logs$</code></span></td></tr> <tr><td>11</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/logs/.*</code></span></td></tr> <tr><td>12</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/\.cpanel$</code></span></td></tr> <tr><td>13</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/\.cpanel/.*</code></span></td></tr> <tr><td>14</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/\.cagefs</code></span></td></tr> <tr><td>15</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/[^/]+/\.cagefs/.*</code></span></td></tr> <tr><td>16</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/virtfs</code></span></td></tr> <tr><td>17</td> <td><span class="notranslate"><code>cpanel</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/virtfs/.*</code></span></td></tr> <tr><td>18</td> <td><span class="notranslate"><code>not_a_userdir</code></span></td> <td><span class="notranslate"><code>^/home/tmp/</code></span></td></tr> <tr><td>19</td> <td><span class="notranslate"><code>not_a_userdir</code></span></td> <td><span class="notranslate"><code>^/home/tmp$</code></span></td></tr> <tr><td>20</td> <td><span class="notranslate"><code>not_a_userdir</code></span></td> <td><span class="notranslate"><code>^/home/ftp/</code></span></td></tr> <tr><td>21</td> <td><span class="notranslate"><code>not_a_userdir</code></span></td> <td><span class="notranslate"><code>^/home/ftp$</code></span></td></tr> <tr><td>22</td> <td><span class="notranslate"><code>not_a_userdir</code></span></td> <td><span class="notranslate"><code>^/home/admin/</code></span></td></tr> <tr><td>23</td> <td><span class="notranslate"><code>not_a_userdir</code></span></td> <td><span class="notranslate"><code>^/home/admin$</code></span></td></tr> <tr><td>24</td> <td><span class="notranslate"><code>quota</code></span></td> <td><span class="notranslate"><code>^/home[^/]*/quota.user$</code></span></td></tr> <tr><td>25</td> <td><span class="notranslate"><code>usermisc</code></span></td> <td><span class="notranslate"><code>/quota.user$</code></span></td></tr> <tr><td>26</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/backups$</code></span></td></tr> <tr><td>27</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/backups/</code></span></td></tr> <tr><td>28</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/imap$</code></span></td></tr> <tr><td>29</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/imap/</code></span></td></tr> <tr><td>30</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/Maildir$</code></span></td></tr> <tr><td>31</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/Maildir/</code></span></td></tr> <tr><td>32</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/domains/[^/]+/logs$</code></span></td></tr> <tr><td>33</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/domains/[^/]+/logs/</code></span></td></tr> <tr><td>34</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/domains/[^/]+/public_ftp$</code></span></td></tr> <tr><td>35</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/domains/[^/]+/public_ftp/</code></span></td></tr> <tr><td>36</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/domains/[^/]+/stats$</code></span></td></tr> <tr><td>37</td> <td><span class="notranslate"><code>users_home</code></span></td> <td><span class="notranslate"><code>^/home/[^/]+/domains/[^/]+/stats/</code></span></td></tr></tbody></table> <p>This information is stored in <span class="notranslate"><code>/etc/container/optimumcache/ignore.d/</code></span>.</p> <p><strong>Skip mask syntax</strong></p> <p>Skip masks use following regexp syntax: <a href="http://www.greenend.org.uk/rjk/tech/regexp.html" target="_blank" rel="noopener noreferrer">http://www.greenend.org.uk/rjk/tech/regexp.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>For example, to disable caching all directories that contain <span class="notranslate"><code>*/cache/*</code></span>, you should use skip masks like:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>/cache/
/cache$
</code></pre></div></div> <p>This information is stored in <span class="notranslate"><code>/etc/container/optimumcache/ignore.d/</code></span></p> <h3 id="optimumcache-configuration-file"><a href="#optimumcache-configuration-file" class="header-anchor">#</a> OptimumCache configuration file</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><p><span class="notranslate"><code>/etc/sysconfig/optimumcache</code></span></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>OPTIMUMCACHE_MNT=/var/cache/optimumcache

 
# Valency to cache

COUNT=0

 
# Minimal file size to cache, default - cache all files

# MINSIZE=0

 
# Minimal page number in file to start caching, default - 1

PAGEMIN=0

 
# Maximum file size to cache, 10485760 (10MB) by default

# MAXSIZE

 
# Interval between caching attempts, default - 5 seconds

# TIMEOUT=7

 
# Adaptive timeout upper limit (seconds)

# MAXTIMEOUT=160

 
# Adaptive timeout multiplicator and divisor

# TIMEOUT_INCR_MUL=2

# TIMEOUT_DECR_DIV=4

 
# Buffer size in KB for 'optimumcache dump', default is 32MB

# DUMP_BUFFER_SIZE=32000

 
# Extra space in %% of requested to purge, default 20%

# PURGEAHEAD=20

 
# Experimental: Eliminate frequent sync to address IO performance

NOIMMSYNC=1

 
# Logging verbosity, default - 1, verbose

# LOGLEVEL=1

 
# occtl --mark-dir or --check operations IO limit, MB/s, default is 5 MB/s

# OCCTL_LVE_IO_LIMIT=5

 
# occtl --mark-dir or --check operations %cpu limit, default is 50% of one CPU core

# OCCTL_LVE_SPEED_LIMIT=50

 
# Lve ID to associate limits with

# LVEID=5

 
# Collect perf statistics in /var/log/optimumcache_perf. Default is enabled.

# PERF_LOG_ENABLED=1
</code></pre></div></div> <h3 id="command-line-interface"><a href="#command-line-interface" class="header-anchor">#</a> Command-line interface</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><p>OptimumCache is controlled using <span class="notranslate"><code>occtl</code></span> command line utility.</p> <p><strong>Usage:</strong></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>occtl.py    [-h] [--move-ploop param [param ...]] [--check] [--verbose]

            [--init-ploop [param [param ...]]] [--resize-ploop New Size]

            [--disable-ploop] [--enable-ploop] [--mount-ploop]

            [--unmount-ploop] [--delete-ploop] [--unmark-all]

            [--mark-dir Path [Path ...]] [--unmark-dir Path [Path ...]]

            [--recursive]  [--add-skip-mask Regex]

            [--remove-skip-mask Id|Tag] [--list-skip-mask] [--silent]

            [--ignore-unmount-failure] [--no-lve-limits] [--foreground]

            [--ploop-status] [--remount-cached-points] [--purge]

            [--cancel-pending-jobs] [--report [Period]]

            [--recommend-minmax-size]
</code></pre></div></div> <p>Display numbers/percents of cached files:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>optimumcache stat
</code></pre></div></div> <p>or</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>optimumcache stat /home
</code></pre></div></div> <p>To display statistic for specific mount. In depth display what is being held in cache:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>optimumcache dump [--resolve-filenames] [mount]
</code></pre></div></div> <p>The option <span class="notranslate"><code>--resolve-filenames</code></span> is experimental and may not apply to all output cached entries.</p> <p>Optional Arguments:</p> <table><thead><tr><th></th> <th></th></tr></thead> <tbody><tr><td><span class="notranslate"><code>-h</code></span>, <span class="notranslate"><code>--help</code></span></td> <td>Show this help message and exit.</td></tr> <tr><td><span class="notranslate"><code>--move-ploop param [param ...]</code></span></td> <td>Move cache from one ploop image to <span class="notranslate"><code>/path/to/new/image/location [New Size[KMGT]]</code></span>.</td></tr> <tr><td><span class="notranslate"><code>--check</code></span></td> <td>Check marked files for errors. This task is scheduled as background job, unless <span class="notranslate"><code>--foreground</code></span> is specified.</td></tr> <tr><td><span class="notranslate"><code>--verbose</code></span></td> <td>List what is being checked.</td></tr> <tr><td><span class="notranslate"><code>--init-ploop [param [param ...]]</code></span></td> <td>Create ploop image for the cache <span class="notranslate"><code>[/path/to/ploop/image [ploop_size] | ploop_size]</code></span> - if only one parameter is given, it is considered to be ploop size. Size should be a <span class="notranslate"><code>NUMBER[KMGT]</code></span>.</td></tr> <tr><td><span class="notranslate"><code>--resize-ploop New Size</code></span></td> <td>New Size NUMBER[KMGT].</td></tr> <tr><td><span class="notranslate"><code>--disable-ploop</code></span></td> <td>Disable ploop.</td></tr> <tr><td><span class="notranslate"><code>--enable-ploop</code></span></td> <td>Enable ploop.</td></tr> <tr><td><span class="notranslate"><code>--mount-ploop</code></span></td> <td>Mount ploop image.</td></tr> <tr><td><span class="notranslate"><code>--unmount-ploop</code></span></td> <td>Unmount ploop image.</td></tr> <tr><td><span class="notranslate"><code>--delete-ploop</code></span></td> <td>Delete ploop image. Implies disable ploop, if was enabled.</td></tr> <tr><td><span class="notranslate"><code>--unmark-all</code></span></td> <td>Unmark all marked directories.</td></tr> <tr><td><span class="notranslate"><code>--mark-dir Path [Path ...]</code></span></td> <td>Mark directory for caching.This task is scheduled as background job, unless <span class="notranslate"><code>--foreground</code></span> is specified.</td></tr> <tr><td><span class="notranslate"><code>--unmark-dir Path [Path ...]</code></span></td> <td>Unmark directory for caching.</td></tr> <tr><td><span class="notranslate"><code>--recursive</code></span></td> <td>Is used with mark/unmark dir.</td></tr> <tr><td><span class="notranslate"><code>--add-skip-mask Regex</code></span></td> <td>Regexp to skip files/directories for caching.</td></tr> <tr><td><span class="notranslate"><code>--remove-skip-mask Id|Tag</code></span></td> <td>Remove regexp to skip files/directories by id or tag.</td></tr> <tr><td><span class="notranslate"><code>--list-skip-mask</code></span></td> <td>List regexp to skip files/directories.</td></tr> <tr><td><span class="notranslate"><code>--silent</code></span></td> <td>Do not echo status to stdout/syslog.</td></tr> <tr><td><span class="notranslate"><code>--ignore-unmount-failure</code></span></td> <td>Ignore cannot unmount ploop problem.</td></tr> <tr><td><span class="notranslate"><code>--no-lve-limits</code></span></td> <td>Ignore default LVE limits for <span class="notranslate"><code>--mark-dir</code></span> and <span class="notranslate"><code>--check</code></span> commands. Also implies --foreground.</td></tr> <tr><td><span class="notranslate"><code>--foreground</code></span></td> <td>Don't spawn <span class="notranslate"><code>--mark-dir</code></span> and <span class="notranslate"><code>--check</code></span> commands in background.</td></tr> <tr><td><span class="notranslate"><code>--ploop-status</code></span></td> <td>Check if ploop is mounted.</td></tr> <tr><td><span class="notranslate"><code>--purge</code></span></td> <td>Purge cache storage (takes some time).</td></tr> <tr><td><span class="notranslate"><code>--cancel-pending-jobs</code></span></td> <td>Cancel <span class="notranslate"><code>--mark-dir</code></span> and <span class="notranslate"><code>--check</code></span> commands if were queued or are being run in background.</td></tr> <tr><td><span class="notranslate"><code>--report [Period]</code></span></td> <td>Report statistics for Period (hourly</td></tr></tbody></table> <h3 id="cloudlinux-collect-collect-system-load-statistics"><a href="#cloudlinux-collect-collect-system-load-statistics" class="header-anchor">#</a> cloudlinux-collect: collect system load statistics</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><h4 id="cloudlinux-collectl-quick-start"><a href="#cloudlinux-collectl-quick-start" class="header-anchor">#</a> cloudlinux-collectl: quick start</h4> <p>Installing this package automatically starts system load statistics collection in background. cloudlinux-collectl package has no strict dependency on OptimumCache, thus the statistics is collected regardless of whether OptimumCache is installed or not. The aim of having this package pre-installed is to compare system performance before and after installing OptimumCache, thus to measure OptimumCache effectiveness.</p> <h4 id="install"><a href="#install" class="header-anchor">#</a> Install</h4> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># yum install cloudlinux-collect --enablerepo=cloudlinux-updates-testing
</code></pre></div></div> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>cloudlinux-collectl will be installed automatically on optimumcache upgrade to 0.2-23</p></div><h4 id="measure-web-site-response-time"><a href="#measure-web-site-response-time" class="header-anchor">#</a> Measure web site response time</h4> <p>cloudlinux-collectl can monitor response time for a configurable set of URLs.</p> <p>Start monitoring new URL:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --addurl &lt;alias&gt; &lt;http://url
</code></pre></div></div> <p>Example:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --addurl localhost http://127.0.0.1/index.php
</code></pre></div></div> <p>Try <span class="notranslate"><code>cloudlinux-collectl --help</code></span> for more options.</p> <h4 id="to-watch-what-is-being-collected"><a href="#to-watch-what-is-being-collected" class="header-anchor">#</a> To watch what is being collected</h4> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --test
</code></pre></div></div> <p>Actual logs are compressed with gzip and kept in <span class="notranslate"><code>/var/log/optimumcache/collectl</code></span> directory.</p> <h4 id="statistics-being-collected-in-details"><a href="#statistics-being-collected-in-details" class="header-anchor">#</a> Statistics being collected in details</h4> <p>To monitor what statistics are being collected, try command:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --test
</code></pre></div></div> <p><img src="/images/optimumcachecollect_zoom93.png" alt=""></p> <p>Along with common statistics blocks as <span class="notranslate">CPU</span> , disk usage, <span class="notranslate">inodes</span> cached, there are two blocks of data to watch how effectively OptimumCache is functioning.</p> <p><span class="notranslate"><code>OPTIMUMCACHE DETAIL</code></span> refers to data, which is similar to output of command</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># optimumcache stat
</code></pre></div></div> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>csums:          4964 (99.9%)

             fetched        uncached            cached

inodes:          4967            31               4936    (99.4%)

size:          204177          131072           73104     (35.8%)

RAM:                8              4                4     (50.0%)
</code></pre></div></div> <p>Particularly, the last column percent numbers shall match.</p> <p>The next goes <span class="notranslate"><code>URLSTATTRACKER DETAIL</code></span> block with url response time in milliseconds. Negative values here may pop up unexpectedly. Negative numbers are not milliseconds, but signal about http error response code for that specific url. For instance, -403 will signal for <span class="notranslate"><code>Forbidden</code></span> http error. As for -500 value, it signals not only for <span class="notranslate"><code>Internal Server Error</code></span>, but can be displayed, when there is connection problem with the server, which is specified by the url.</p> <h4 id="statistics-manual-configuration"><a href="#statistics-manual-configuration" class="header-anchor">#</a> Statistics manual configuration</h4> <p><span class="notranslate"><code>URLSTATTRACKER DETAIL</code></span> is the only statistics, which requires manual configuration. Upon clean installation, it has only <span class="notranslate"><code>url_localhost</code></span> preconfigured:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --info
</code></pre></div></div> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>url shortname            url

--------------------         ---

localhost                 http://localhost/
</code></pre></div></div> <p>To add another URL for monitoring:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>## cloudlinux-collect --addurl alt http://192.168.0.102/
</code></pre></div></div> <p>To display URLs being monitored list:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --info
</code></pre></div></div> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>url shortname          url

--------------------          ---

alt                        http://192.168.0.102/

localhost                  http://localhost/
</code></pre></div></div> <p>To skip URL from being tracked run command:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --skip &lt;url short name&gt;
</code></pre></div></div> <h4 id="running-statistics-daemon-collectl-cloudlinux"><a href="#running-statistics-daemon-collectl-cloudlinux" class="header-anchor">#</a> Running statistics daemon: collectl-cloudlinux</h4> <p>cloudlinux-collectl has got collectl package as a dependency. Initd script <span class="notranslate"><code>/etc/init.d/cloudlinux-collectl</code></span> will automatically bring up another instance of collectl named <span class="notranslate"><code>collectl-optimumcache</code></span> . collectl-optimumcache daemon instance has a separate config and does not interfere with other running pre-configure collectl daemon (if any).</p> <p>As it was mentioned, collectl-optimumcache daemon starts automatically on package install, then on server restart events, kicked by regular Initd script <span class="notranslate"><code>/etc/init.d/cloudlinux-collectl</code></span>. Thus, checking the daemon status, stop, restart is trivial:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># service cloudlinux-collect status
collectl-optimumcache (pid  1745) is running…
</code></pre></div></div> <p>To start /stop:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># service cloudlinux-collect &lt; start | stop &gt;
</code></pre></div></div> <h4 id="analyzing-the-results"><a href="#analyzing-the-results" class="header-anchor">#</a> Analyzing the results</h4> <p>The statistics is being collected into files named <span class="notranslate"><code>%hostname%-%datetime%.raw.gz</code></span> under directory <span class="notranslate"><code>/var/log/cloudlinux-collect</code></span>.</p> <p>To convert those info format suitable for loading into Excel, LibreOffice Calc, another data mining tool, run the command:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># cloudlinux-collect --genplotfiles
</code></pre></div></div> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>Generate fresh plot files in

         /var/log/cloudlinux-collect/plotfiles

</code></pre></div></div> <h3 id="uninstall-optimumcache"><a href="#uninstall-optimumcache" class="header-anchor">#</a> Uninstall OptimumCache</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><p>To uninstall OptimumCache, run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>service optimumcache stop
occtl --delete-ploop
:&gt;/var/share/optimumcache_store
yum remove optimumcache
</code></pre></div></div> <p>If available, reboot server</p> <p>After the reboot <span class="notranslate"><code>pfcache= mount</code></span> options will disappear by themselves.</p> <p>For OptimumCache version prior 0.2-11, uninstalling via rpm package manager does not automatically removes away ploop image. That is because not always possible to unmount it properly due to kernel dependency. If there is no luck with unmounting ploop, then the server will have to be rebooted and will need to remove ploop files manually:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># rm /var/share/optimumcache/optimumcache.image
# rm /var/share/optimumcache/DiskDescriptor.xml
# rm /var/share/optimumcache/DiskDescriptor.xml.lck
</code></pre></div></div>
 or
<div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># rm /path/to/ploop/image/file
# rm /path/to/ploop/image/DiskDescriptor.xml
# rm /path/to/ploop/image/DiskDescriptor.xml.lck
</code></pre></div></div> <p>For OptimumCache version 0.2-11 and later, ploop image will be removed automatically during uninstall. If ploop unmount issue prevents doing that, ploop image clean up will be scheduled after next server reboot.</p> <p>If uninstall OptimumCache process lasts for too long, please find the solution in Troubleshooting section of this document.</p> <h3 id="troubleshooting"><a href="#troubleshooting" class="header-anchor">#</a> Troubleshooting</h3> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>OPTIMUMCACHE IS NO LONGER SUPPORTED</p></div><h4 id="installing-for-fs-is-different-from-ext4"><a href="#installing-for-fs-is-different-from-ext4" class="header-anchor">#</a> Installing for FS is different from Ext4</h4> <p>For now Ext4 is the only supported file system type. If a host has no Ext4 filesystem mounted, OptimumCache package installation will be abandoned:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>Preparing packages for installation...

Cannot continue: Ext4 partition is the only supported by OptimiumCache, there is no one in fstab

error: %pre(optimumcache-0.1-22.el6.cloudlinux.x86_64) scriptlet failed, exit status 1

error:   install: %pre scriptlet failed (2), skipping
</code></pre></div></div> <p>Also, an attempt to add for caching directory, which does not reside on Ext4, will fail:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --mark-dir /home --recursive

mount: / not mounted already, or bad option

optimumcache: Can not mount device. rc[8192]

Error: mark[1]: /usr/bin/optimumcache mark --recursive /home
</code></pre></div></div> <h4 id="yum-fails-to-install-perl-rpms-coming-with-optimumcache"><a href="#yum-fails-to-install-perl-rpms-coming-with-optimumcache" class="header-anchor">#</a> Yum fails to install Perl rpms coming with OptimumCache</h4> <p>If got this error with <span class="notranslate"><code>yum install optimumcache</code></span></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>Error: Package: cloudlinux-collect-0.1-6.el6.noarch (cloudlinux-x86_64-server-6)

Requires: perl(Config::Tiny)

Error: Package: cloudlinux-collect-0.1-6.el6.noarch (cloudlinux-x86_64-server-6)

Requires: perl(IO::Socket::SSL)

Error: Package: cloudlinux-collect-0.1-6.el6.noarch (cloudlinux-x86_64-server-6)

Requires: perl(YAML::Tiny)

Error: Package: cloudlinux-collect-0.1-6.el6.noarch (cloudlinux-x86_64-server-6)

Requires: perl(IPC::Run)

You could try using --skip-broken to work around the problem

You could try running: rpm -Va --nofiles --nodigest
</code></pre></div></div> <p>Most probably you have excluded <span class="notranslate"><code>perl*</code></span> packages in <span class="notranslate"><code>/etc/yum.conf</code></span> file, in this case to install OptimumCache run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># yum install optimumcache --disableexcludes=all
</code></pre></div></div> <h4 id="optimumcache-prior-0-2-23-cannot-unmount-old-ploop-image"><a href="#optimumcache-prior-0-2-23-cannot-unmount-old-ploop-image" class="header-anchor">#</a> OptimumCache prior 0.2-23: Cannot unmount old ploop image</h4> <p>This is well-known ploop problem, which may result in failing such actions as resizing or moving ploop in OptimumCache. To workaround this problem use <span class="notranslate"><code>--ignore-unmount-failure</code></span> with <span class="notranslate"><code>--move-ploop</code></span></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --move-ploop --ignore-unmount-failure
</code></pre></div></div> <p>As for resizing ploop, use flavor of <span class="notranslate"><code>--move-ploop</code></span> command instead:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --move-ploop /path/to/new/image/file [size GB] --ignore-unmount-failure
</code></pre></div></div> <p>For your changes to take effect, the server has to be rebooted. Upon reboot, you may clean up manually old ploop image file and <span class="notranslate"><code>DiskDescriptor.xml</code></span> file, which resides in the same directory along with old image.</p> <h4 id="high-io-rate"><a href="#high-io-rate" class="header-anchor">#</a> High IO rate</h4> <p>High <span class="notranslate">IO</span> problem was fixed in latest version of OptimumCache (version 0.2-6). The fix is to eliminate <span class="notranslate"><code>superflows fsync()</code></span> calls in OptimumCache operations. To activate this fix in existing installation, flag <span class="notranslate"><code>NOIMMSYNC=1</code></span> has to be manually set in <span class="notranslate"><code>/etc/syscoconfig/optimumcache</code></span>.</p> <p>To ensure that this parameter is set <span class="notranslate"><code>ON</code></span> in the config, set <span class="notranslate"><code>LOGLEVEL=2</code></span> and execute <span class="notranslate"><code>service optimumcache restart</code></span>. You will see something like this:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code>optimumcache[1770]: Hash-size: 100000000 min-size: 0 max-size: 18446744071562067968
optimumcache[1770]: Count: 0 Timeout: 5
optimumcache[1770]: Max Timeout: 160 Adaptive Timeout Mul/Div: 2/4
optimumcache[1770]: Iolimit: 0 iopslimit: 0
optimumcache[1770]: No immediate fsync: Yes
optimumcache[1771]: Starting OptimumCache monitor
</code></pre></div></div> <p>To update to version 0.2-6, run:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># yum update optimumcache --enablerepo=cloudlinux-updates-testing
</code></pre></div></div> <h4 id="high-cpu-utilization"><a href="#high-cpu-utilization" class="header-anchor">#</a> High CPU utilization</h4> <p>Once it is detected that OptimumCache overuses <span class="notranslate">CPU</span>, it is useful to check, whether checksums reindexing process is running. When reindexing is running, high <span class="notranslate">CPU</span> usage is ok, as far it will certainly drop down after reindexing finished.</p> <p>Can be checked in <span class="notranslate"><code>/var/log/messages</code></span></p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># grep Reindexing /var/log/messages

Feb  4 17:00:55 CL-default-2 occtl[2654]: Reindexing started
</code></pre></div></div> <p>If the last line from the output is not <span class="notranslate"><code>Reindexing finished…</code></span>, than indexing is in progress.</p> <p>Also, can be checked via command <span class="notranslate"><code>occtl --report</code></span>, watch if <span class="notranslate"><code>PFL_REINDEX_NUM_FILES</code></span> and <span class="notranslate"><code>PFL_REINDEX_THOUGHPUT_KB</code></span> identifiers are present in the last series of data:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --report
- Period starts at: 2015-02-04 17:00
Period Stat:

PFL_ATTACHED:                    170318
PFL_CREATED:                     161583
PFL_ERR_BAD_CSUM:                176
PFL_ERR_INODES:                  879
PFL_FAILED_TO_ATTACH_PEER:       791
PFL_FAILED_TO_ATTACH_PEER_EBUSY: 791

PFL_INODE_IN:                    406167
PFL_PAGEMIN_FILTERED_OUT:        233418
PFL_PAGEMIN_USED:                136082
PFL_REINDEX_NUM_FILES:           192810
PFL_REINDEX_THOUGHPUT_KB:        2904007
PFL_RESTART:                     1
</code></pre></div></div> <h4 id="uninstalling-optimumcache-lasts-for-too-long"><a href="#uninstalling-optimumcache-lasts-for-too-long" class="header-anchor">#</a> Uninstalling OptimumCache lasts for too long</h4> <p>Uninstalling OptimumCache takes time because of files unmark process, which lasts proportionally to number of files, previously marked for caching with <span class="notranslate"><code>occtl --mark-dir...</code></span>. If you see, that <span class="notranslate"><code>yum remove optimumcache</code></span> command is stuck and you have no time to wait for it to finish, or <span class="notranslate">IO</span> load, caused by unmarking files, is undesirable for you, open another console terminal and invoke:</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --cancel-pending-jobs
</code></pre></div></div> <p>This command will cancel unmark operation, being run by yum under the hood. So that yum uninstall package transaction will complete very soon.</p> <h4 id="‘failed-to-attach-peer-invalid-argument’-appears-in-syslog"><a href="#‘failed-to-attach-peer-invalid-argument’-appears-in-syslog" class="header-anchor">#</a> ‘Failed to attach peer: Invalid argument’ appears in syslog</h4> <p>Rather rare problem, try to forcibly update <code>optimumcache_s</code> with ploop status.</p> <div class="notranslate"><div class="language- extra-class"><pre class="language-text"><code># occtl --remount-cached-points
</code></pre></div></div> <h2 id="tpe-extension"><a href="#tpe-extension" class="header-anchor">#</a> TPE extension</h2> <p><strong>TPE (Trusted Path Execution)</strong></p> <p>The kernel supports <span class="notranslate"> TPE </span> feature out of the box. You can configure it using following files:
</p><div class="notranslate"><p></p> <div class="language- extra-class"><pre class="language-text"><code>·        /proc/sys/kernel/grsecurity/grsec_lock
·        /proc/sys/kernel/grsecurity/tpe
·        /proc/sys/kernel/grsecurity/tpe_gid
·        /proc/sys/kernel/grsecurity/tpe_restrict_all
</code></pre></div></div> <p>To enable <span class="notranslate"> TPE </span> feature in a standard way just add following to the end of your <span class="notranslate"> /etc/sysctl.conf </span></p><div class="notranslate"><p></p> <div class="language- extra-class"><pre class="language-text"><code>#GRsecurity 
kernel.grsecurity.tpe = 1 
kernel.grsecurity.tpe_restrict_all = 1 
kernel.grsecurity.grsec_lock = 1  
</code></pre></div></div> <p>And do:
</p><div class="notranslate"><p></p> <div class="language- extra-class"><pre class="language-text"><code># sysctl -p
</code></pre></div></div> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>Once you set grsec_lock to 1, you will not be able to change TPE options without reboot.</p></div><p>This <span class="notranslate">Trusted Path Execution</span> feature was adopted from <span class="notranslate">grsecurity</span>.</p> <h2 id="cpu-limits"><a href="#cpu-limits" class="header-anchor">#</a> CPU limits</h2> <div class="tip custom-block"><p class="custom-block-title">Note</p><p>Deprecated</p> <p>This limit is no longer used, and <span class="notranslate"><a href="/limits/#speed-limits">SPEED</a></span> is used instead</p></div><h3 id="cpu-limits-before-lve-utils-1-4"><a href="#cpu-limits-before-lve-utils-1-4" class="header-anchor">#</a> CPU limits before lve-utils 1.4</h3> <p><span class="notranslate"> CPU </span> Limits are set by <span class="notranslate"> CPU </span> and <span class="notranslate"> NCPU </span> parameters. <span class="notranslate"> CPU </span> specifies the % of total <span class="notranslate"> CPU </span> of the server available to LVE. <span class="notranslate"> NCPU </span> specifies the number of cores available to LVE. The smallest of the two is used to define how much <span class="notranslate"> CPU </span> power will be accessible to the customer.</p> <table><thead><tr><th></th> <th></th> <th></th> <th></th></tr></thead> <tbody><tr><td>Cores Per Server</td> <td><span class="notranslate"> CPU </span> Limit</td> <td><span class="notranslate"> NCPU </span> Limit</td> <td>Real limit</td></tr> <tr><td>1</td> <td>25%</td> <td>1</td> <td>25% of 1 core</td></tr> <tr><td>2</td> <td>25%</td> <td>1</td> <td>50% of 1 core</td></tr> <tr><td>2</td> <td>25%</td> <td>2</td> <td>50% of 1 core</td></tr> <tr><td>4</td> <td>25%</td> <td>1</td> <td>100% of 1 core (full core)</td></tr> <tr><td>4</td> <td>25%</td> <td>2</td> <td>1 core</td></tr> <tr><td>4</td> <td>50%</td> <td>1</td> <td>1 core</td></tr> <tr><td>4</td> <td>50%</td> <td>2</td> <td>2 cores</td></tr> <tr><td>8</td> <td>25%</td> <td>1</td> <td>1 core</td></tr> <tr><td>8</td> <td>25%</td> <td>2</td> <td>2 cores</td></tr> <tr><td>8</td> <td>50%</td> <td>2</td> <td>2 cores</td></tr> <tr><td>8</td> <td>50%</td> <td>3</td> <td>3 cores</td></tr></tbody></table> <p>When user hits <span class="notranslate"> CPU </span> limit, processes within that limit are slowed down. For example, if you set your <span class="notranslate"> CPU </span> limit to 10%, and processes inside LVE want to use more then 10% they will be throttled (put to sleep) to make sure they don't use more then 10%. In reality, processes don't get <span class="notranslate"> CPU </span> time above the limit, and it happens much more often then 1 second interval, but the end result is that processes are slowed down so that their usage is never above the <span class="notranslate"> CPU </span> limit set.</p></div> <div class="page-edit"><div class="edit-link"><a href="https://github.com/cloudlinux/cloudlinux-doc/edit/dev/docs/deprecated/README.md" target="_blank" rel="noopener noreferrer">Edit this page</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <!----></div> <div class="back-to-top" data-v-5366e0dd><a href="/deprecated/#app" class="nav-arrow top back-to-top__link" data-v-5366e0dd></a></div> </div> <div class="footer" data-v-58ab2eba><div data-v-58ab2eba><a href="https://cloudlinux.com" data-v-58ab2eba><img src="/assets/img/we-are-cloudlinux.783ed390.svg" alt="We are Cloudlinux" data-v-58ab2eba></a></div> <div class="footer-company-title" data-v-58ab2eba>2021. CloudLinux Inc</div> <div data-v-58ab2eba><div data-v-58ab2eba><a href="https://cloudlinux.zendesk.com/hc/sections/115001344329-How-do-I" target="_blank" data-v-58ab2eba>How to</a></div><div data-v-58ab2eba><a href="https://www.cloudlinux.com/getting-started-with-cloudlinux-os" target="_blank" data-v-58ab2eba>Getting started</a></div><div data-v-58ab2eba><a href="https://cloudlinux.zendesk.com/hc/en-us/requests/new" target="_blank" data-v-58ab2eba>Contact support</a></div><div data-v-58ab2eba><a href="https://www.cloudlinux.com/blog" target="_blank" data-v-58ab2eba>Blog</a></div></div> <div class="social" data-v-58ab2eba><span class="footer-social-text" data-v-58ab2eba>Stay in touch</span> <a href="https://www.facebook.com/cloudlinux/" target="_blank" data-v-58ab2eba><img src="/fb.png" class="footer-social-logo" data-v-58ab2eba></a><a href="https://twitter.com/cloudlinuxos/" target="_blank" data-v-58ab2eba><img src="/tw.png" class="footer-social-logo" data-v-58ab2eba></a><a href="https://linkedin.com/company/cloudlinux" target="_blank" data-v-58ab2eba><img src="/in.png" class="footer-social-logo" data-v-58ab2eba></a><a href="https://www.youtube.com/channel/UCZ3YMHWnMP7TaxlXVay5-aw" target="_blank" data-v-58ab2eba><img src="/ytube.png" class="footer-social-logo" data-v-58ab2eba></a></div></div> <!----></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.da36fadb.js" defer></script><script src="/assets/js/13.14de4ed9.js" defer></script>
  </body>
</html>
